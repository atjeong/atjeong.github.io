<!DOCTYPE html>
<html lang="en-us">
  <head>
    <title>Jeonghoon Park</title>

    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">    
<meta name="viewport" content="width=device-width,minimum-scale=1">
<meta name="description" content="Research Archive from Jeonghoon">
<meta name="generator" content="Hugo 0.100.2" />


  <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">


<link rel="stylesheet" href="/css/style.css">



<link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon" />

 
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'your-google-analytics-id', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>




  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>



  
    <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Jeonghoon Park" />
    <link href="/index.xml" rel="feed" type="application/rss+xml" title="Jeonghoon Park" />
  


  </head>

  <body>
    <nav class="navigation">
	
	<a href="/posts">Archive</a>
	<a href="/tags">Tags</a>
	<a href="/about">About</a>

	

	
	  <a class="button" href="https://atjeong.github.io/index.xml">Subscribe</a>
	
</nav>


    <main class="main">
      
<header class="profile">
    
        <img class="avatar" alt="avatar" src="/images/avatar.png" />
    

    <h1>Jeonghoon Park</h1>
    
    
      <h2>(test cv page) I am PhD student at Korea Advanced Institute of Science and Technology (KAIST) advised by Professor Jaegul Choo.</h2>
    
</header>

<div id="list-page">
    
    
    
        
        
        <section class="item">
          <div>
            <h1 class="title"><a href='/post/bias_ensemble/'>BiasEnsemble: Revisiting the Importance of Amplifying Bias for Debiasing</a></h1>
            <div class ="date">
                <time datetime="2022-07-11 16:43:25 &#43;0900 KST">Jul 11, 2022</time>  
            </div>
          </div>

          
              <div class="summary">Jungsoo Lee*, Jeonghoon Park*, Daeyoung Kim*, Junyoung Lee, Edward Choi, Jaegul Choo 🔗 Abstract 🔗In image classification, “debiasing” aims to train a classifier to be less susceptible to dataset bias, the strong correlation between peripheral attributes of data samples and a target class. For example, even if the frog class in the dataset mainly consists of frog images with a swamp background (i.e., bias-aligned samples), a debiased classifier should be able to correctly classify a frog at a beach (i.</div>
          

        </section>
    
        
        
        <section class="item">
          <div>
            <h1 class="title"><a href='/post/deepedge/'>Deep Edge-Aware Interactive Colorization against Color Bleeding Effects</a></h1>
            <div class ="date">
                <time datetime="2021-11-13 16:00:04 &#43;0900 KST">Nov 13, 2021</time>  
            </div>
          </div>

          
              <div class="summary">ICCV 2021 (Oral) 🎉 🔗Eungyeup Kim*, Sanghyeon Lee*, Jeonghoon Park*, Somi choi, Choonghyun Seo, Jaegul Choo 🔗 Abstract 🔗Deep image colorization networks often suffer from the color-bleeding artifact, a problematic color spreading near the boundaries between adjacent objects. The color-bleeding artifacts debase the reality of generated outputs, limiting the applicability of colorization models on a practical application. Although previous approaches have tackled this problem in an automatic manner, they often generate imperfect outputs because their enhancements are available only in limited cases, such as having a high contrast of gray-scale value in an input image.</div>
          

        </section>
    
        
        
        <section class="item">
          <div>
            <h1 class="title"><a href='/post/ood_ssl/'>Evaluation of Out-of-Distribution Detection Performance of Self-Supervised Learning in a Controllable Environment</a></h1>
            <div class ="date">
                <time datetime="2020-11-13 16:43:02 &#43;0900 KST">Nov 13, 2020</time>  
            </div>
          </div>

          
              <div class="summary">NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and Practice 🔗Jeonghoon Park*, Kyungmin Jo*, Daehoon Gwak*, Jimin Hong, Jaegul Choo, Edward Choi 🔗 Abstract 🔗We evaluate the out-of-distribution (OOD) detection performance of self-supervised learning (SSL) techniques with a new evaluation framework. Unlike the previous evaluation methods, the proposed framework adjusts the distance of OOD samples from the in-distribution samples. We evaluate an extensive combination of OOD detection algorithms on three different implementations of the proposed framework using simulated samples, images, and text.</div>
          

        </section>
    

    


</div>

    </main>
    
    <footer id="footer">
    

    <div class="copyright">
    
        © Copyright 2021 Jeonghoon
    
    </div>

    
</footer>



  </body>
</html>
